{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Text Processing_Feature Extraction (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sinudeshmukh/Data-Science/blob/main/Text_Processing_Feature_Extraction_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrVjDqN-L-V-"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import string # special operations on strings\n",
        "import spacy # language models\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from matplotlib import pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hZrVrjUL-WA"
      },
      "source": [
        "#!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce-pCivTL-WB"
      },
      "source": [
        "import pandas\n",
        "book=pd.read_csv(\"apple.txt\",error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFCdOKJJL-WC"
      },
      "source": [
        "book"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CC-5wKbL-WC"
      },
      "source": [
        "book = [x.strip() for x in book.x] # remove both the leading and the trailing characters\n",
        "book = [x for x in book if x]      # removes empty strings, because they are considered in Python as False\n",
        "book[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQMlO7-L-WD"
      },
      "source": [
        "# Joining the list into one string/text\n",
        "text = ' '.join(book)\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i75A9NB-L-WD"
      },
      "source": [
        "#Punctuation\n",
        "no_punc_text = text.translate(str.maketrans('', '', string.punctuation)) #with arguments (x, y, z) where 'x' and 'y'\n",
        "# must be equal-length strings and characters in 'x'\n",
        "# are replaced by characters in 'y'. 'z'\n",
        "# is a string (string.punctuation here)\n",
        "no_punc_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNo_osnrL-WE"
      },
      "source": [
        "#Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "text_tokens = word_tokenize(no_punc_text)\n",
        "print(text_tokens[0:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZ-_utfL-WE"
      },
      "source": [
        "len(text_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okr3_M4fL-WF"
      },
      "source": [
        "#Remove stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "my_stop_words = stopwords.words('english')\n",
        "my_stop_words.append('the')\n",
        "no_stop_tokens = [word for word in text_tokens if not word in my_stop_words]\n",
        "print(no_stop_tokens[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL7cxpDJL-WF"
      },
      "source": [
        "#Noramalize the data\n",
        "lower_words = [x.lower() for x in no_stop_tokens]\n",
        "print(lower_words[0:25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCD_hHHQL-WF"
      },
      "source": [
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "stemmed_tokens = [ps.stem(word) for word in lower_words]\n",
        "print(stemmed_tokens[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UINJ9l32L-WG"
      },
      "source": [
        "#!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK6u5g42L-WG"
      },
      "source": [
        "# NLP english language model of spacy library\n",
        "nlp = spacy.load('en') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le4OaPUtL-WG"
      },
      "source": [
        "# lemmas being one of them, but mostly POS, which will follow later\n",
        "doc = nlp(' '.join(no_stop_tokens))\n",
        "print(doc[0:40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5bnY1aLL-WH"
      },
      "source": [
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(lemmas[0:25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXXiuSVJL-WH"
      },
      "source": [
        "#### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxssgJiGL-WI"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(lemmas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Hnz9CBL-WI"
      },
      "source": [
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wkGEVKFyL-WI"
      },
      "source": [
        "print(vectorizer.get_feature_names()[50:100])\n",
        "print(X.toarray()[50:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NJhGZGjL-WJ"
      },
      "source": [
        "print(X.toarray().shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyhY-QObL-WJ"
      },
      "source": [
        "#### Let's see how can bigrams and trigrams can be included here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TowWjKGLL-WJ"
      },
      "source": [
        "vectorizer_ngram_range = CountVectorizer(analyzer='word',ngram_range=(1,3),max_features = 100)\n",
        "bow_matrix_ngram =vectorizer_ngram_range.fit_transform(book)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeZWjrCwL-WK"
      },
      "source": [
        "print(vectorizer_ngram_range.get_feature_names())\n",
        "print(bow_matrix_ngram.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3jTBhcDL-WK"
      },
      "source": [
        "#### TFidf vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eobNj0idL-WK"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer_n_gram_max_features = TfidfVectorizer(norm=\"l2\",analyzer='word', ngram_range=(1,3), max_features = 500)\n",
        "tf_idf_matrix_n_gram_max_features =vectorizer_n_gram_max_features.fit_transform(book)\n",
        "print(vectorizer_n_gram_max_features.get_feature_names())\n",
        "print(tf_idf_matrix_n_gram_max_features.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwO2Il-4L-WL"
      },
      "source": [
        "####  Generate wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YNknjarL-WL"
      },
      "source": [
        "# Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "# Define a function to plot word cloud\n",
        "def plot_cloud(wordcloud):\n",
        "    # Set figure size\n",
        "    plt.figure(figsize=(40, 30))\n",
        "    # Display image\n",
        "    plt.imshow(wordcloud) \n",
        "    # No axis details\n",
        "    plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tRYR1oYL-WL"
      },
      "source": [
        "# Generate wordcloud\n",
        "stopwords = STOPWORDS\n",
        "stopwords.add('will')\n",
        "wordcloud = WordCloud(width = 3000, height = 2000, background_color='black', max_words=100,colormap='Set2',stopwords=stopwords).generate(text)\n",
        "# Plot\n",
        "plot_cloud(wordcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbvPSJ5GL-WM"
      },
      "source": [
        "# Save image\n",
        "#wordcloud.to_file(\"wordcloud.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}